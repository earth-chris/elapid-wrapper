#! /usr/bin/env python
import argparse
import importlib
# hack some encoding stuff because fml
import sys

import geopandas as gpd
import numpy as np
import pandas as pd
from shapely.geometry import Point

importlib.reload(sys)
sys.setdefaultencoding("utf-8")


############################
# setting the command line argument parser

# load the world boundaries shapefile for data subsetting
world = gpd.read_file(gpd.datasets.get_path("naturalearth_lowres"))
world = world[["geometry", "name", "continent"]]

# get the unique continent and country names for user-specified subsetting
countries = world["name"].unique().tolist()
continents = world["continent"].unique().tolist()

# set the default taxa as a list to parse for the arguments
taxa = ["kingdom", "phylum", "class", "order", "family", "genus", "species"]

# create the argument parser to feed input options
parser = argparse.ArgumentParser(description="Cleans and reprojects GBIF data")

# set input/output file arguments
parser.add_argument("-i", "--input", help="path to GBIF CSV file", type=str, required=True)
parser.add_argument("-o", "--output", help="path to the output vector", type=str, required=True)

# now various flags and arguments
parser.add_argument("-e", "--epsg", help="the output projection (in gdal-readable format)", default="4326")
parser.add_argument(
    "-t",
    "--taxonomic_level",
    help="the taxonomic group that must have data to be included",
    default="genus",
    choices=taxa,
    metavar="taxonomic_level",
)
parser.add_argument("-p", "--precision", help="the minimum allowable spatial precision (in meters)", default=None)
parser.add_argument("-y", "--min_year", help="the earliest year to grab data from", default=2000)

# allow subsetting by country or continent
parser.add_argument(
    "--continent", help="subset the data by continent", default=None, choices=continents, nargs="+", metavar=""
)
parser.add_argument(
    "--country", help="subset the data by country", default=None, choices=countries, nargs="+", metavar=""
)

# finall, parse the arguments
args = parser.parse_args()


############################
# set the defaults for which data to keep, which to toss

# first, set a bunch of defaults for which columns and records to keep
col_names = [
    "kingdom",
    "phylum",
    "class",
    "order",
    "family",
    "genus",
    "species",
    "decimalLatitude",
    "decimalLongitude",
    "coordinateUncertaintyInMeters",
    "year",
    "basisOfRecord",
    "datasetKey",
]

col_types = {
    "kingdom": str,
    "phylum": str,
    "class": str,
    "order": str,
    "family": str,
    "genus": str,
    "species": str,
    "decimalLatitude": str,
    "decimalLongitude": str,
    "coordinateUncertaintyInMeters": str,
    "year": str,
    "basisOfRecord": str,
    "datasetKey": str,
}

observation_type = [
    "HUMAN_OBSERVATION",
    "PRESERVED_SPECIMEN",
    "SPECIMEN",
    "OBSERVATION",
    "LITERATURE",
    "LIVING_SPECIMEN",
    "MATERIAL_SAMPLE",
    "MACHINE_OBSERVATION",
]

valid_by = [args.taxonomic_level, "decimalLatitude", "decimalLongitude"]
duplicate_by = ["species", "genus", "decimalLatitude", "decimalLongitude"]

# set the columns worth keeping
final_columns = ["kingdom", "phylum", "class", "order", "family", "genus", "species", "year"]


############################
# start reading the data and processing
print("[ STATUS ]: Starting gbif-to-vector")
print("[ STATUS ]: Reading input file: {}".format(args.input))

# read the data into memory and subset to just the relevant columns
full = pd.read_csv(args.input, header=0, sep="\t", usecols=col_names, dtype=col_types, error_bad_lines=False)

# then convert the numberic data types from strings
full["decimalLatitude"] = pd.to_numeric(full["decimalLatitude"], errors="coerce")
full["decimalLongitude"] = pd.to_numeric(full["decimalLongitude"], errors="coerce")
full["year"] = pd.to_numeric(full["year"], errors="coerce")
full["coordinateUncertaintyInMeters"] = pd.to_numeric(full["coordinateUncertaintyInMeters"], errors="coerce")

# start cleaning data
print("[ STATUS ]: Removing bad data points")

# keep only valid records
full = full.dropna(subset=valid_by)

# drop records that are too inpercise
if args.precision is not None:
    full = full.loc[full["coordinateUncertaintyInMeters"] <= args.precision]

# drop points with 0.0 lat/lon
full = full.loc[full["decimalLatitude"] != 0.0]
full = full.loc[full["decimalLongitude"] != 0.0]

# drop it like its old
full = full.loc[full["year"] >= args.min_year]

# set observation types
full = full[full["basisOfRecord"].isin(observation_type)]

# finally, remove duplicate points and clear the index
full = full[np.invert(full.duplicated(subset=duplicate_by))]
full.reset_index(drop=True, inplace=True)

# now, we'll convert it to a geopandas dataframe
geometry = [Point(xy) for xy in zip(full.decimalLongitude, full.decimalLatitude)]
crs = {"init": "epsg:4326"}
gdf = gpd.GeoDataFrame(full[final_columns], crs=crs, geometry=geometry)

# then intersect these data with country boundaries to ensure we're landlubbing
print("[ STATUS ]: Converting to GeoPandas format")
landlubbers = gpd.sjoin(gdf, world, op="within")

# subset by continent or country if set
if args.continent is not None:
    print("[ STATUS ]: Subsetting by continent(s): {}".format(", ".join(args.continent)))
    inds = landlubbers["continent"].isin(args.continent)
    landlubbers = landlubbers[inds]

if args.country is not None:
    print("[ STATUS ]: Subsetting by country(s): {}".format(", ".join(args.country)))
    inds = landlubbers["name"].isin(args.country)
    landlubbers = landlubbers[inds]

# then reproject the data if not using the standard wgs-84 lat/lon
if args.epsg != 4326:
    print("[ STATUS ]: Reprojecting to EPSG: {}".format(args.epsg))
    landlubbers.to_crs(epsg=args.epsg, inplace=True)

# then finally subset and rename the output columns
landlubbers.drop("index_right", 1, inplace=True)
landlubbers.rename(columns={"name": "country"}, inplace=True)

# export the output file
landlubbers.to_file(args.output, driver="ESRI Shapefile")
print("[ STATUS ]: Finished cleaning GBIF data!")
print("[ STATUS ]: See output file: {}".format(args.output))
